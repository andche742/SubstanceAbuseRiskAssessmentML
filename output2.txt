Fitting 5 folds for each of 84 candidates, totalling 420 fits

 Unbalanced results for Alcohol
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        29
           1       0.92      1.00      0.96       347

    accuracy                           0.92       376
   macro avg       0.46      0.50      0.48       376
weighted avg       0.85      0.92      0.89       376

/Users/andrewchen/Desktop/SubstanceAbuseRiskAssessmentML/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/Users/andrewchen/Desktop/SubstanceAbuseRiskAssessmentML/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/Users/andrewchen/Desktop/SubstanceAbuseRiskAssessmentML/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

 Balanced results for Alcohol
              precision    recall  f1-score   support

           0       0.19      0.38      0.26        29
           1       0.94      0.87      0.90       347

    accuracy                           0.83       376
   macro avg       0.57      0.62      0.58       376
weighted avg       0.89      0.83      0.85       376

Fitting 5 folds for each of 84 candidates, totalling 420 fits

 Unbalanced results for Amphet
              precision    recall  f1-score   support

           0       0.79      0.91      0.84       276
           1       0.56      0.32      0.41       100

    accuracy                           0.75       376
   macro avg       0.67      0.61      0.63       376
weighted avg       0.73      0.75      0.73       376


 Balanced results for Amphet
              precision    recall  f1-score   support

           0       0.89      0.74      0.81       276
           1       0.51      0.74      0.60       100

    accuracy                           0.74       376
   macro avg       0.70      0.74      0.71       376
weighted avg       0.79      0.74      0.75       376

Fitting 5 folds for each of 84 candidates, totalling 420 fits

 Unbalanced results for Amyl
              precision    recall  f1-score   support

           0       0.92      1.00      0.96       347
           1       0.00      0.00      0.00        29

    accuracy                           0.92       376
   macro avg       0.46      0.50      0.48       376
weighted avg       0.85      0.92      0.89       376


 Balanced results for Amyl
              precision    recall  f1-score   support

           0       0.95      0.73      0.83       347
           1       0.14      0.52      0.22        29

    accuracy                           0.72       376
   macro avg       0.54      0.63      0.52       376
weighted avg       0.89      0.72      0.78       376

Fitting 5 folds for each of 84 candidates, totalling 420 fits
/Users/andrewchen/Desktop/SubstanceAbuseRiskAssessmentML/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/Users/andrewchen/Desktop/SubstanceAbuseRiskAssessmentML/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/Users/andrewchen/Desktop/SubstanceAbuseRiskAssessmentML/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

 Unbalanced results for Benzos
              precision    recall  f1-score   support

           0       0.73      0.90      0.81       253
           1       0.62      0.33      0.43       123

    accuracy                           0.71       376
   macro avg       0.67      0.61      0.62       376
weighted avg       0.69      0.71      0.68       376


 Balanced results for Benzos
              precision    recall  f1-score   support

           0       0.85      0.69      0.76       253
           1       0.54      0.75      0.63       123

    accuracy                           0.71       376
   macro avg       0.69      0.72      0.69       376
weighted avg       0.75      0.71      0.72       376

Fitting 5 folds for each of 84 candidates, totalling 420 fits

 Unbalanced results for Caff
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        19
           1       0.95      1.00      0.97       357

    accuracy                           0.95       376
   macro avg       0.47      0.50      0.49       376
weighted avg       0.90      0.95      0.92       376


 Balanced results for Caff
              precision    recall  f1-score   support

           0       0.07      0.16      0.10        19
           1       0.95      0.89      0.92       357

    accuracy                           0.86       376
   macro avg       0.51      0.53      0.51       376
weighted avg       0.91      0.86      0.88       376

Fitting 5 folds for each of 84 candidates, totalling 420 fits
/Users/andrewchen/Desktop/SubstanceAbuseRiskAssessmentML/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/Users/andrewchen/Desktop/SubstanceAbuseRiskAssessmentML/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/Users/andrewchen/Desktop/SubstanceAbuseRiskAssessmentML/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

 Unbalanced results for Cannabis
              precision    recall  f1-score   support

           0       0.74      0.82      0.78       167
           1       0.84      0.77      0.80       209

    accuracy                           0.79       376
   macro avg       0.79      0.79      0.79       376
weighted avg       0.80      0.79      0.79       376


 Balanced results for Cannabis
              precision    recall  f1-score   support

           0       0.81      0.73      0.77       167
           1       0.80      0.87      0.83       209

    accuracy                           0.81       376
   macro avg       0.81      0.80      0.80       376
weighted avg       0.81      0.81      0.80       376

Fitting 5 folds for each of 84 candidates, totalling 420 fits

 Unbalanced results for Choc
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        13
           1       0.97      1.00      0.98       363

    accuracy                           0.97       376
   macro avg       0.48      0.50      0.49       376
weighted avg       0.93      0.97      0.95       376

/Users/andrewchen/Desktop/SubstanceAbuseRiskAssessmentML/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/Users/andrewchen/Desktop/SubstanceAbuseRiskAssessmentML/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/Users/andrewchen/Desktop/SubstanceAbuseRiskAssessmentML/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

 Balanced results for Choc
              precision    recall  f1-score   support

           0       0.03      0.08      0.04        13
           1       0.96      0.90      0.93       363

    accuracy                           0.87       376
   macro avg       0.50      0.49      0.49       376
weighted avg       0.93      0.87      0.90       376

Fitting 5 folds for each of 84 candidates, totalling 420 fits

 Unbalanced results for Coke
              precision    recall  f1-score   support

           0       0.80      0.89      0.84       286
           1       0.47      0.31      0.37        90

    accuracy                           0.75       376
   macro avg       0.64      0.60      0.61       376
weighted avg       0.72      0.75      0.73       376


 Balanced results for Coke
              precision    recall  f1-score   support

           0       0.88      0.72      0.79       286
           1       0.44      0.70      0.54        90

    accuracy                           0.71       376
   macro avg       0.66      0.71      0.66       376
weighted avg       0.78      0.71      0.73       376

Fitting 5 folds for each of 84 candidates, totalling 420 fits

 Unbalanced results for Crack
              precision    recall  f1-score   support

           0       0.94      1.00      0.97       354
           1       0.00      0.00      0.00        22

    accuracy                           0.94       376
   macro avg       0.47      0.50      0.48       376
weighted avg       0.89      0.94      0.91       376


 Balanced results for Crack
              precision    recall  f1-score   support

           0       0.96      0.86      0.91       354
           1       0.16      0.41      0.23        22

    accuracy                           0.84       376
   macro avg       0.56      0.64      0.57       376
weighted avg       0.91      0.84      0.87       376

Fitting 5 folds for each of 84 candidates, totalling 420 fits
/Users/andrewchen/Desktop/SubstanceAbuseRiskAssessmentML/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/Users/andrewchen/Desktop/SubstanceAbuseRiskAssessmentML/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/Users/andrewchen/Desktop/SubstanceAbuseRiskAssessmentML/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

 Unbalanced results for Ecstasy
              precision    recall  f1-score   support

           0       0.83      0.86      0.84       270
           1       0.61      0.54      0.57       106

    accuracy                           0.77       376
   macro avg       0.72      0.70      0.71       376
weighted avg       0.76      0.77      0.77       376


 Balanced results for Ecstasy
              precision    recall  f1-score   support

           0       0.86      0.73      0.79       270
           1       0.50      0.70      0.58       106

    accuracy                           0.72       376
   macro avg       0.68      0.71      0.69       376
weighted avg       0.76      0.72      0.73       376

Fitting 5 folds for each of 84 candidates, totalling 420 fits

 Unbalanced results for Heroin
              precision    recall  f1-score   support

           0       0.92      1.00      0.96       345
           1       0.00      0.00      0.00        31

    accuracy                           0.92       376
   macro avg       0.46      0.50      0.48       376
weighted avg       0.84      0.92      0.88       376


 Balanced results for Heroin
              precision    recall  f1-score   support

           0       0.95      0.80      0.87       345
           1       0.20      0.55      0.29        31

    accuracy                           0.78       376
   macro avg       0.58      0.68      0.58       376
weighted avg       0.89      0.78      0.82       376

Fitting 5 folds for each of 84 candidates, totalling 420 fits
/Users/andrewchen/Desktop/SubstanceAbuseRiskAssessmentML/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/Users/andrewchen/Desktop/SubstanceAbuseRiskAssessmentML/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/Users/andrewchen/Desktop/SubstanceAbuseRiskAssessmentML/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

 Unbalanced results for Ketamine
              precision    recall  f1-score   support

           0       0.87      1.00      0.93       327
           1       0.00      0.00      0.00        49

    accuracy                           0.87       376
   macro avg       0.43      0.50      0.47       376
weighted avg       0.76      0.87      0.81       376


 Balanced results for Ketamine
              precision    recall  f1-score   support

           0       0.92      0.70      0.80       327
           1       0.23      0.61      0.34        49

    accuracy                           0.69       376
   macro avg       0.58      0.66      0.57       376
weighted avg       0.83      0.69      0.74       376

Fitting 5 folds for each of 84 candidates, totalling 420 fits
/Users/andrewchen/Desktop/SubstanceAbuseRiskAssessmentML/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/Users/andrewchen/Desktop/SubstanceAbuseRiskAssessmentML/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/Users/andrewchen/Desktop/SubstanceAbuseRiskAssessmentML/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

 Unbalanced results for Legalh
              precision    recall  f1-score   support

           0       0.85      0.83      0.84       252
           1       0.67      0.70      0.69       124

    accuracy                           0.79       376
   macro avg       0.76      0.77      0.76       376
weighted avg       0.79      0.79      0.79       376


 Balanced results for Legalh
              precision    recall  f1-score   support

           0       0.86      0.79      0.83       252
           1       0.64      0.74      0.69       124

    accuracy                           0.78       376
   macro avg       0.75      0.77      0.76       376
weighted avg       0.79      0.78      0.78       376

Fitting 5 folds for each of 84 candidates, totalling 420 fits

 Unbalanced results for LSD
              precision    recall  f1-score   support

           0       0.87      0.96      0.91       290
           1       0.77      0.50      0.61        86

    accuracy                           0.85       376
   macro avg       0.82      0.73      0.76       376
weighted avg       0.84      0.85      0.84       376


 Balanced results for LSD
              precision    recall  f1-score   support

           0       0.93      0.82      0.87       290
           1       0.56      0.78      0.65        86

    accuracy                           0.81       376
   macro avg       0.74      0.80      0.76       376
weighted avg       0.84      0.81      0.82       376

Fitting 5 folds for each of 84 candidates, totalling 420 fits

 Unbalanced results for Meth
              precision    recall  f1-score   support

           0       0.87      0.96      0.91       309
           1       0.63      0.33      0.43        67

    accuracy                           0.85       376
   macro avg       0.75      0.64      0.67       376
weighted avg       0.83      0.85      0.83       376


 Balanced results for Meth
              precision    recall  f1-score   support

           0       0.92      0.78      0.84       309
           1       0.40      0.67      0.50        67

    accuracy                           0.76       376
   macro avg       0.66      0.73      0.67       376
weighted avg       0.82      0.76      0.78       376

Fitting 5 folds for each of 84 candidates, totalling 420 fits

 Unbalanced results for Mushrooms
              precision    recall  f1-score   support

           0       0.88      0.84      0.86       276
           1       0.61      0.67      0.64       100

    accuracy                           0.80       376
   macro avg       0.74      0.76      0.75       376
weighted avg       0.80      0.80      0.80       376


 Balanced results for Mushrooms
              precision    recall  f1-score   support

           0       0.87      0.78      0.82       276
           1       0.52      0.67      0.59       100

    accuracy                           0.75       376
   macro avg       0.69      0.72      0.70       376
weighted avg       0.77      0.75      0.76       376

Fitting 5 folds for each of 84 candidates, totalling 420 fits

 Unbalanced results for Nicotine
              precision    recall  f1-score   support

           0       0.72      0.58      0.64       163
           1       0.72      0.83      0.77       213

    accuracy                           0.72       376
   macro avg       0.72      0.70      0.70       376
weighted avg       0.72      0.72      0.71       376


 Balanced results for Nicotine
              precision    recall  f1-score   support

           0       0.65      0.69      0.67       163
           1       0.75      0.72      0.73       213

    accuracy                           0.70       376
   macro avg       0.70      0.70      0.70       376
weighted avg       0.71      0.70      0.71       376

Fitting 5 folds for each of 84 candidates, totalling 420 fits

 Unbalanced results for VSA
              precision    recall  f1-score   support

           0       0.95      1.00      0.98       358
           1       0.00      0.00      0.00        18

    accuracy                           0.95       376
   macro avg       0.48      0.50      0.49       376
weighted avg       0.91      0.95      0.93       376

/Users/andrewchen/Desktop/SubstanceAbuseRiskAssessmentML/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/Users/andrewchen/Desktop/SubstanceAbuseRiskAssessmentML/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/Users/andrewchen/Desktop/SubstanceAbuseRiskAssessmentML/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

 Balanced results for VSA
              precision    recall  f1-score   support

           0       0.97      0.89      0.92       358
           1       0.15      0.39      0.21        18

    accuracy                           0.86       376
   macro avg       0.56      0.64      0.57       376
weighted avg       0.93      0.86      0.89       376
